# Developer Guide

## Project Structure

The project follows a standard python package structure under `src/tempdata`.

```
src/tempdata/
├── aggregate/          # Logic for growing hourly -> daily data
├── clean/              # Data cleaning and QC
├── eval/               # Evaluation framework (Core)
│   ├── config.py       # Configuration schemas
│   ├── runner.py       # Main orchestration
│   ├── metrics.py      # MAE, RMSE, calibration logic
│   └── models.py       # Forecasting models (Ridge, Passthrough)
├── features/           # Feature engineering (Seasonal, Rolling)
├── fetch/              # Data acquisition (NOAA, ERA5, Open-Meteo)
└── schemas/            # Pandera schemas for data validation
```

## Setup

1.  **Install locally**:
    ```bash
    pip install -e ".[dev,eval]"
    ```
    This installs the package in editable mode with development filtering/evaluation dependencies.

2.  **Environment Variables**:
    -   `CDSAPI_URL` and `CDSAPI_KEY`: Required for ERA5 fetching (or use `~/.cdsapirc`).

## Testing

We use `pytest` for testing.

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_eval_runner.py
```

## Adding New Features

### Adding a New Model
1.  Extend the `Forecaster` protocol in `src/tempdata/eval/models.py`.
2.  Update `ModelConfig` in `src/tempdata/eval/config.py` to include the new model type name.
3.  Update the factory function `create_forecaster` in `models.py`.

### Adding a New Metric
1.  Implement the metric function in `src/tempdata/eval/metrics.py`.
2.  Add it to the `compute_forecast_metrics` function or the `EvalMetrics` dataclass.
